{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8Hmp8JbVNv4ZVpsvR7Frk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorMm1/Ono-Image-Processing/blob/master/Part_B_of_Final_Project_of_Image_Processing_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Project Image Processing, Ono College - B.Sc Computer Science**\n",
        "## Google Colab Notebook 3/3\n",
        "\n",
        "### Students:\n",
        "- StudentName = 'Dor Menahem', StudentID = '318687746', StudentMobile = '052-8028427'\n",
        "- StudentName = 'Nir Barash', StudentID = '207541434', StudentMobile = '054-3172167'\n",
        "\n"
      ],
      "metadata": {
        "id": "Hc7M7cbnbkI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from google.colab import drive\n",
        "import ast\n",
        "\n"
      ],
      "metadata": {
        "id": "UXrL7Q1ZgBg4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "def setup_google_drive(dataset_folder=\"/content/drive/My Drive/Part_B_DataSet\"):\n",
        "    # Mount Google Drive\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    # Define paths to train and test folders\n",
        "    train_folder = os.path.join(dataset_folder, \"train\")\n",
        "    test_folder = os.path.join(dataset_folder, \"test\")\n",
        "\n",
        "    return train_folder, test_folder\n",
        "\n",
        "# Example usage\n",
        "train_folder, test_folder = setup_google_drive()\n",
        "print(\"Train folder:\", train_folder)\n",
        "print(\"Test folder:\", test_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv6CzfkSfwvK",
        "outputId": "c57c261e-b521-4944-b96a-4fb34b57f035"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n",
            "Train folder: /content/drive/My Drive/Part_B_DataSet/train\n",
            "Test folder: /content/drive/My Drive/Part_B_DataSet/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import os\n",
        "\n",
        "class Metadata:\n",
        "    def __init__(self, shapes, line):\n",
        "        self.shapes = shapes\n",
        "        self.line = line\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Iterate over the shapes attribute\n",
        "        return iter(self.shapes)\n",
        "\n",
        "def parse_metadata(metadata_text):\n",
        "    # Extract shape metadata\n",
        "    shape_metadata = metadata_text['shape_metadata']\n",
        "    line_metadata = metadata_text['line_metadata']\n",
        "\n",
        "    # Create a Metadata object\n",
        "    parsed_metadata = Metadata(shape_metadata, line_metadata)\n",
        "\n",
        "    return parsed_metadata\n",
        "\n",
        "def load_metadata(dataset_folder, num_images):\n",
        "    \"\"\"\n",
        "    Load metadata for each image from the .txt files.\n",
        "\n",
        "    Args:\n",
        "    - dataset_folder (str): Path to the dataset folder.\n",
        "    - num_images (int): Total number of images in the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - list: List containing Metadata objects for each image.\n",
        "    \"\"\"\n",
        "    metadata = []\n",
        "    for i in range(num_images):\n",
        "        # Load metadata from the corresponding .txt file\n",
        "        txt_filename = f\"{i}.jpg.txt\"\n",
        "        txt_filepath = os.path.join(dataset_folder, txt_filename)\n",
        "        with open(txt_filepath, \"r\") as f:\n",
        "            metadata_text = ast.literal_eval(f.read())\n",
        "            metadata.append(parse_metadata(metadata_text))\n",
        "    return metadata\n",
        "\n",
        "num_images = 5600\n",
        "metadata = load_metadata(train_folder, num_images)"
      ],
      "metadata": {
        "id": "2SG8RbPAS3zI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metadata example Metadata objects:\")\n",
        "print(metadata[0].shapes)\n",
        "print(metadata[0].line)\n",
        "print(\"Amount of metadata objects:\")\n",
        "print(len(metadata))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi6BHIAe9bl1",
        "outputId": "81f53a63-98fd-46b7-a2a3-e25fd101b096"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata example Metadata objects:\n",
            "[{'shape_type': 'half_circle', 'color': 165, 'size': 10, 'position': [112, 59]}, {'shape_type': 'triangle', 'color': 97, 'size': 18, 'position': [57, 41]}]\n",
            "{'shape_type': 'line', 'color': 14, 'a': 1.65625, 'b': -124.0}\n",
            "Amount of metadata objects:\n",
            "5600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # Resize the image to 128x128 -- image was generated 128X128 but never the less\n",
        "    image = cv2.resize(image, (128, 128))\n",
        "    # Normalize the image\n",
        "    image = image / 255.0\n",
        "    return image\n",
        "\n",
        "def get_label(metadata):\n",
        "    # Check if shapes length is 1 and shape is not a circle\n",
        "    if len(metadata.shapes) == 1 and metadata.shapes[0]['shape_type'] != 'circle':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def create_data_tuples(image_directory, metadata_objects):\n",
        "    data_tuples = []\n",
        "    for i, metadata in enumerate(metadata_objects):\n",
        "        # Construct the image filename\n",
        "        image_filename = f\"{i}.jpg\"\n",
        "        image_path = os.path.join(image_directory, image_filename)\n",
        "        # Check if the image file exists\n",
        "        if os.path.exists(image_path):\n",
        "            # Load and preprocess the image\n",
        "            image = process_image(image_path)\n",
        "            # Get the label\n",
        "            label = get_label(metadata)\n",
        "            # Append the tuple (image, metadata, label) to the data list\n",
        "            data_tuples.append((image, metadata, label))\n",
        "    return data_tuples\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "image_directory = train_folder\n",
        "metadata_objects = metadata  # List of metadata objects\n",
        "\n",
        "# Generate data tuples\n",
        "data_tuples = create_data_tuples(image_directory, metadata_objects)\n",
        "\n",
        "# Example of accessing the first data tuple\n",
        "image, metadata, label = data_tuples[0]\n",
        "print(\"Image size:\", image.shape)\n",
        "print(\"Label:\", label)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBRwzEfMS6vV",
        "outputId": "c66b65c5-cda3-4763-bde5-8412d4b7148a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: (128, 128)\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define your neural network architecture\n",
        "def create_model():\n",
        "    # Image input\n",
        "    image_input = layers.Input(shape=(128, 128, 1))\n",
        "    # Metadata input\n",
        "    metadata_input = layers.Input(shape=(len(metadata_features)+1,))\n",
        "\n",
        "    # Image processing layers\n",
        "    conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "    maxpool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "    conv2 = layers.Conv2D(64, (3, 3), activation='relu')(maxpool1)\n",
        "    maxpool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "    flatten1 = layers.Flatten()(maxpool2)\n",
        "\n",
        "    # Concatenate image and metadata features\n",
        "    concat = layers.concatenate([flatten1, metadata_input])\n",
        "\n",
        "    # Dense layers for classification\n",
        "    dense1 = layers.Dense(64, activation='relu')(concat)\n",
        "    output = layers.Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "    model = models.Model(inputs=[image_input, metadata_input], outputs=output)\n",
        "    return model\n",
        "\n",
        "# train_data: list of tuples (image, metadata, label)\n",
        "train_data = data_tuples\n",
        "# test_data: list of tuples (image, metadata, label)\n",
        "metadata_objects_test = load_metadata(test_folder, 1400)\n",
        "test_data = create_data_tuples(test_folder, metadata_objects_test)\n"
      ],
      "metadata": {
        "id": "bzHrR2hLV-Le"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metadata features\n",
        "metadata_features = ['color', 'size', 'position']\n",
        "\n",
        "# Extract features and labels from train and test data\n",
        "def extract_features(metadata):\n",
        "    if metadata.shapes:  # Check if shapes list is not empty\n",
        "        # Extract numerical features from metadata\n",
        "        color = metadata.shapes[0]['color']\n",
        "        size = metadata.shapes[0]['size']\n",
        "        position_x, position_y = metadata.shapes[0]['position']\n",
        "        # Return extracted features as a list\n",
        "        return [color, size, position_x, position_y]\n",
        "    else:\n",
        "        return [0, 0, 0, 0]  # Return default values\n",
        "\n",
        "\n",
        "X_train_images = np.array([data[0] for data in train_data])\n",
        "X_train_metadata = np.array([extract_features(data[1]) for data in train_data])  # Assuming a function extract_features() extracts numerical features from Metadata\n",
        "y_train_labels = np.array([data[2] for data in train_data])\n",
        "\n",
        "X_test_images = np.array([data[0] for data in test_data])\n",
        "X_test_metadata = np.array([extract_features(data[1]) for data in test_data])  # Assuming a function extract_features() extracts numerical features from Metadata\n",
        "y_test_labels = np.array([data[2] for data in test_data])\n",
        "\n",
        "# Normalize image data\n",
        "X_train_images = X_train_images / 255.0\n",
        "X_test_images = X_test_images / 255.0"
      ],
      "metadata": {
        "id": "DRdRvxXvLk7f"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model\n",
        "model = create_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([X_train_images, X_train_metadata], y_train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate([X_test_images, X_test_metadata], y_test_labels)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsfEvISKFxYh",
        "outputId": "b25f978c-e5e8-4d4e-b82f-a598cda7713e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "140/140 [==============================] - 108s 766ms/step - loss: 0.3131 - accuracy: 0.9190 - val_loss: 0.3006 - val_accuracy: 0.9098\n",
            "Epoch 2/10\n",
            "140/140 [==============================] - 100s 716ms/step - loss: 0.2890 - accuracy: 0.9192 - val_loss: 0.2969 - val_accuracy: 0.9098\n",
            "Epoch 3/10\n",
            "140/140 [==============================] - 103s 735ms/step - loss: 0.2753 - accuracy: 0.9192 - val_loss: 0.2911 - val_accuracy: 0.9098\n",
            "Epoch 4/10\n",
            "140/140 [==============================] - 103s 739ms/step - loss: 0.2782 - accuracy: 0.9192 - val_loss: 0.2922 - val_accuracy: 0.9098\n",
            "Epoch 5/10\n",
            "140/140 [==============================] - 104s 743ms/step - loss: 0.2713 - accuracy: 0.9192 - val_loss: 0.2901 - val_accuracy: 0.9098\n",
            "Epoch 6/10\n",
            "140/140 [==============================] - 102s 725ms/step - loss: 0.2714 - accuracy: 0.9192 - val_loss: 0.2950 - val_accuracy: 0.9098\n",
            "Epoch 7/10\n",
            "140/140 [==============================] - 104s 739ms/step - loss: 0.2731 - accuracy: 0.9192 - val_loss: 0.2920 - val_accuracy: 0.9098\n",
            "Epoch 8/10\n",
            "140/140 [==============================] - 102s 729ms/step - loss: 0.2742 - accuracy: 0.9192 - val_loss: 0.2953 - val_accuracy: 0.9098\n",
            "Epoch 9/10\n",
            "140/140 [==============================] - 100s 714ms/step - loss: 0.2727 - accuracy: 0.9192 - val_loss: 0.2892 - val_accuracy: 0.9098\n",
            "Epoch 10/10\n",
            "140/140 [==============================] - 101s 726ms/step - loss: 0.2682 - accuracy: 0.9192 - val_loss: 0.2888 - val_accuracy: 0.9098\n",
            "44/44 [==============================] - 10s 218ms/step - loss: 0.2706 - accuracy: 0.9164\n",
            "Test Loss: 0.2705914080142975, Test Accuracy: 0.9164285659790039\n"
          ]
        }
      ]
    }
  ]
}